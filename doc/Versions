Schema Version Control

-------------------------------------------------------------------------------
(May 2020)
This document is currently a design specification as full version control has
not yet been implemented in Wyseman.

Objectives:
-------------------------------------------------------------------------------
Wyseman really has three fundamental purposes:

- Schema Authoring
  Help the developer make changes to the schema, quickly apply them and 
  evaluate their function in a tight, efficient design iteration cycle.
  This currently works quite well.

- Runtime Access
  Provide applications with an API to the database that is oriented around
  accessing tables, views, functions, reports and the schema data dictionary.
  This is also working well.

- Version Control
  Allow applications to seamlessly update older versions of a schema without
  requiring a lot of fiddling by end users.  This has not yet been implemented
  in a satisfactory way.

-------------------------------------------------------------------------------
Version Control
(Feb 2021)

The initial approach of the Ruby/JS port (as of 1.0.17) was to have a "release"
number for each official version of the schema.  This approach has several
problems:

- It can be difficult to know if a given instantiation of an object in the DB
  belongs to one version or another.  We have the wm.release() function to
  rely on.  But how will we really update an entire schema from onen release to
  the next?
  
  I originally envisioned a precompiled schema file (schema-1.sql) which would
  have all the SQL in it to instantiate a schema of a given version.  But it
  lacked the "development" schema such as wm.objects.  The plan was to then
  have schema-2.sql, schema-3.sql and so forth.
  
  But this would also require migration scripts such as migrate-1-2.sql,
  migrate-2-3.sql and so forth so an app could work with a DB instance at
  release level 1 and promote it all the way up to whatever the current version
  should be.

- Schema components should be capable of being drawn from third-party libraries
  (such as wyselib).  This makes versioning even more complicated.  If my
  version is release 3, but something changes in wyselib, how do I know to
  promote my application release?  If I have everything populated in the
  wm.objects table, I might be able to detect that difference.  But it would be
  difficult to tell simply from a running instance of the database.
  
This seems to lead to the conclusion that every object should really have its 
own version control.  If any given object could be uniquely identified by a hash
of its:

  - Create code
  - Dependencies
  - Version number

we could count on knowing that the object we have running is the one we want.

Then, the notion of a "release" would just be a manifest of all the objects that
belong in that given release, along with the hashes we expect them each to have.
This seems to simplify a great number of issues.

The issues we are left with are:

- How to track an object that was part of a prior release, but has now been
  removed.  Hopefully, it is enough to just have it absent from the manifest.
  During development, the user would have to wisely use the --prune switch to
  decide if/when to remove an object that is not part of a current parse.

- How to save information about previous versions of database objects.  Maybe
  this is just a variant of the previous point.  However, it is clear: the DB
  meta schema is fully capable of tracking multiple versions of objects. But
  the flat files are not.  They only have the current, latest snapshot.  If
  we delete our database, we will lose all history.  There needs to be some
  archive, part of the schema directly that stores all the old history.

- How to reliaably migrate data from one version of a table to the next.

-------------------------------------------------------------------------------
Table Data Migration

Here are the main issues:

- New Constraints
  The problem here is, the user's table may contain data that worked under the
  older, more permissive constraints but won't be allowed under the new
  constraints.  Likely the best we could hope for would be to register a set
  of queries that would hopefully reveal rows that won't be allowed under the
  new set of constraints.
  
  A savy developer could use wyseman to run these checks against the production
  database to see what data might have to be massaged prior to running an 
  update script.  Better approach would be an API for apps to do this on their
  own and just report data problems to the user.

- New Columns
  This can easily be handled by proper default values in the new schema.  The
  main problem will be if the developer creates a "not null" constraint but no
  default value.

- Missing Columns
  If a column is renamed or removed rom one version to the next, we really need
  some kind of alter script to run just prior to the drop/create cycle on the
  table.  This will be done in a transaction so it can be safe from other
  accesses going on.  But it will really be up to the developer to write this
  correctly so that data dumped from the old table can be re-imported into the
  new one.
  
  For a renamed column, it is as simple as "alter table rename column x to y."
  
  For a deleted column, there is a good chance there is data in that column we
  may expect to be presented in some new way in another new column.  The
  developer would have to create the new column, insert data into it based on
  a query of the old, obsolete column, and then drop the old column.

For purposes of wyseman, we will divide this into two categories:

- Version Tests
- Version Migrations

Both of these apply only to tables and no other kind of object.

Version tests are limited to queries that will reveal records that have to be 
manually changed before there is any hope of upgrading versions.

Version Migrations are any arbitrary SQL that must be executed in a transaction
immediately before a drop/create cycle on the table.

Our meta schema will need to have provisions for storing and maintaining these
along with the tables they belong to.

-------------------------------------------------------------------------------
History:

It is proposed that Wyseman generate a file in the application schema folder
called Wyseman.hist.  This file would be a JSON structure containing all past
history a part of prior version commits, but not represented in the set of
schema files (whether specific to the app, or drawn from any external schema
libraries).

We will then create two more parseable objects: tabtest, tabmod.

The tabtest will be expected to contain a single select (use a union for more
complex cases) that should reveal human-identifiable record ID's for any data
records that don't pass muster for new table constraints.

The tabmod will contain any amount of SQL modification code required.

When accessed, these objects will get integrated into the history file as well.
The developer will then have to remove the file they were contained in (or make
sure not to parse it again).

These deltas will be cumulative from one committed version to the next.  In
other words, the system will remember all tabtests and tabmods processed since
the last version commit so they can all be performed, in order when going from
one version to the next.

-------------------------------------------------------------------------------
Bootstrap Schema:

Finally, we should probably resign ourselves to the idea that a production DB
will have to contain wm.objects.  There needs to be a way to know, at least, 
the version and hash for each intantiated object (if not also its create code).
-------------------------------------------------------------------------------
